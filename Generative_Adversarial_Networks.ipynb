{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPDDPlGQnzjqTNrN2HiNQZU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Armin-Abdollahi/Generative-Adversarial-Networks/blob/main/Generative_Adversarial_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Dense,Flatten,Reshape\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "88GjaeDZ7qo6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_rows=28\n",
        "img_cols=28\n",
        "channels=1\n",
        "\n",
        "img_shape = (img_rows,img_cols,channels)\n",
        "\n",
        "zdim=100"
      ],
      "metadata": {
        "id": "VXGDdSAB74ve"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_gen(img_shape,zdim):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(128,input_dim=zdim))\n",
        "  model.add(LeakyReLU(alpha=0.01))\n",
        "  model.add(Dense(28*28*1))\n",
        "  model.add(Reshape(img_shape))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "LwFJby3G76o3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dis(img_shape):\n",
        "  model=Sequential()\n",
        "  model.add(Flatten(input_shape=img_shape))\n",
        "  model.add(Dense(128))\n",
        "  model.add(LeakyReLU(alpha=0.01))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "UAQFFGsE78ky"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_gan(gen,dis):\n",
        "  model = Sequential()\n",
        "  model.add(gen)\n",
        "  model.add(dis)\n",
        "\n",
        "  return model\n",
        "\n",
        "dis_v = build_dis(img_shape)\n",
        "dis_v.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
        "\n",
        "gen_v = build_gen(img_shape,zdim)\n",
        "dis_v.trainable=False\n",
        "gan_v = build_gan(gen_v,dis_v)\n",
        "gan_v.compile(loss='binary_crossentropy',optimizer=Adam())\n",
        "\n",
        "losses=[]\n",
        "accuracies=[]\n",
        "iteration_checks=[]"
      ],
      "metadata": {
        "id": "42IhjuQ18EQq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "tG2PPx4pHs4P"
      },
      "outputs": [],
      "source": [
        "def train(iterations,batch_size,interval):\n",
        "  (Xtrain, _),(_, _) = mnist.load_data()\n",
        "  Xtrain = Xtrain/127.5 - 1.0\n",
        "  Xtrain = np.expand_dims(Xtrain,axis=3)\n",
        "\n",
        "  real = np.ones((batch_size,1))\n",
        "  fake = np.zeros((batch_size, 1))\n",
        "\n",
        "  for iteration in range(iterations):\n",
        "    ids = np.random.randint(0,Xtrain.shape[0],batch_size)\n",
        "    imgs = Xtrain[ids]\n",
        "\n",
        "    z=np.random.normal(0,1,(batch_size,100))\n",
        "    gen_imgs = gen_v.predict(z)\n",
        "\n",
        "    dloss_real = dis_v.train_on_batch(imgs,real)\n",
        "    dloss_fake = dis_v.train_on_batch(gen_imgs, fake)\n",
        "\n",
        "    dloss,accuracy = 0.5 * np.add(dloss_real,dloss_fake)\n",
        "\n",
        "    z = np.random.normal(0, 1, (batch_size, 100))\n",
        "    gloss = gan_v.train_on_batch(z,real)\n",
        "\n",
        "  if (iteration+1) % interval == 0:\n",
        "    losses.append((dloss,gloss))\n",
        "    accuracies.append(100.0*accuracy)\n",
        "    iteration_checks.append(iteration+1)\n",
        "\n",
        "  print(\"%d [D loss: %f , acc: %.2f] [G loss: %f]\" %\n",
        "  (iteration+1,dloss,100.0*accuracy,gloss))\n",
        "  show_images(gen_v)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(gen):\n",
        "  z = np.random.normal(0, 1, (16, 100))\n",
        "  gen_imgs = gen.predict(z)\n",
        "  gen_imgs = 0.5*gen_imgs + 0.5\n",
        "\n",
        "  fig,axs = plt.subplots(4,4,figsize=(4,4),sharey=True,sharex=True)\n",
        "\n",
        "  cnt=0\n",
        "  for i in range(4):\n",
        "    for j in range(4):\n",
        "      axs[i, j].imshow(gen_imgs[cnt,:,:,0],cmap='gray')\n",
        "      axs[i, j].axis('off')\n",
        "      cnt+=1\n",
        "\n",
        "  fig.show()\n",
        "\n",
        "  train(5000,128,1000)"
      ],
      "metadata": {
        "id": "CXA7v1ay8N8y"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}